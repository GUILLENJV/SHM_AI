{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GUILLENJV/SHM_AI/blob/master/Hyperparameters_by_Bayesian_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Optimization"
      ],
      "metadata": {
        "id": "ndwgPlN4HEto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como recordatorio rápido, el ajuste de hiperparámetros es una parte fundamental de un proyecto de aprendizaje automático. Hay dos tipos de hiperparámetros:\n",
        "\n",
        "1. Hiperparámetros estructurales : definen la arquitectura general de un modelo (por ejemplo, número de unidades ocultas , número de capas )\n",
        "\n",
        "2. Hiperparámetros del optimizador: influyen en la velocidad y la calidad del entrenamiento (por ejemplo , tasa de aprendizaje y tipo de optimizador , tamaño del lote , número de épocas )"
      ],
      "metadata": {
        "id": "T2MS4Rn4bULh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afortunadamente, el sintonizador Keras proporciona un sintonizador de optimización bayesiana . En lugar de buscar todas las combinaciones posibles, el sintonizador de optimización bayesiana sigue un proceso iterativo, en el que elige las primeras al azar. Luego, en función del rendimiento de esos hiperparámetros, el sintonizador bayesiano selecciona el siguiente mejor posible.\n",
        "\n",
        "Así, cada elección de hiperparámetros depende de los intentos previos. El número de iteraciones para elegir el siguiente conjunto de hiperparámetros en función del historial y la evaluación del rendimiento continúa hasta que el sintonizador encuentra la mejor combinación o agota el número máximo de intentos . Podemos configurar esto con el argumento ' max_trials '.\n"
      ],
      "metadata": {
        "id": "WiQZfUKCbdfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of learned embedding encoding for a neural network\n",
        "from numpy import unique\n",
        "import numpy\n",
        "from numpy import array\n",
        "import pandas as pd\n",
        "import datetime \n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.regularizers import l1\n",
        "from keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "metadata": {
        "id": "YEN_sUdX19iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carga los datos\n",
        "df = pd.read_csv('631d8277776f1d001a21e6eb.csv') \n",
        "df = df.drop_duplicates()\n",
        "\n",
        "df[\"visitor_device_hardware_family\"] = df[\"visitor_device_hardware_family\"].apply(str)\n",
        "df[\"visitor_device_hardware_model\"] = df[\"visitor_device_hardware_model\"].apply(str)\n",
        "df[\"visitor_device_os_version\"] = df[\"visitor_device_os_version\"].apply(str)\n",
        "df[\"visitor_device_hardware_family\"] = df[\"visitor_device_hardware_family\"].apply(str)\n",
        "df[\"visitor_device_hardware_model\"] = df[\"visitor_device_hardware_model\"].apply(str)\n",
        "df[\"visitor_device_os_version\"] = df[\"visitor_device_os_version\"].apply(str)\n",
        "df[\"visitor_tokens_adh\"] = df[\"visitor_tokens_adh\"].apply(str)\n",
        "df[\"visitor_tokens_cadid\"] = df[\"visitor_tokens_cadid\"].apply(str)\n",
        "df[\"converted_yes\"] = df[\"converted_yes\"].apply(str)\n",
        "df[\"converted_no\"] = df[\"converted_no\"].apply(str)\n",
        "\n",
        "# Imputamos la variable \n",
        "df['visitor_device_os_vendor'].fillna(df['visitor_device_os_vendor'].mode()[0], inplace=True)\n",
        "df['campaign_id'].fillna(df['campaign_id'].mode()[0], inplace=True)\n",
        "df['visitor_device_hardware_vendor'].fillna(df['visitor_device_hardware_vendor'].mode()[0], inplace=True)\n",
        "df['visitor_device_browser'].fillna(df['visitor_device_browser'].mode()[0], inplace=True)\n",
        "df['traffic_source_id'].fillna(df['traffic_source_id'].mode()[0], inplace=True)\n",
        "df['landing_page_id'].fillna(df['landing_page_id'].mode()[0], inplace=True)\n",
        "df['visitor_device_os_family'].fillna(df['visitor_device_os_family'].mode()[0], inplace=True)\n",
        "df['visitor_device_type'].fillna(df['visitor_device_type'].mode()[0], inplace=True)\n",
        "df['visitor_geo_location_countryCode'].fillna(df['visitor_geo_location_countryCode'].mode()[0], inplace=True)\n",
        "df['visitor_geo_location_regionName'].fillna(df['visitor_geo_location_regionName'].mode()[0], inplace=True)\n",
        "df['visitor_tokens_adi'].fillna(df['visitor_tokens_adi'].mode()[0], inplace=True)\n",
        "df['visitor_geo_location_isp'].fillna(df['visitor_geo_location_isp'].mode()[0], inplace=True)\n",
        "df['visitor_geo_location_connection_type'].fillna(df['visitor_geo_location_connection_type'].mode()[0], inplace=True)\n",
        "df['visitor_geo_location_cityName'].fillna(df['visitor_geo_location_cityName'].mode()[0], inplace=True)\n",
        "\n",
        "df = df.drop(['landing_pages_group_id','visitor_tokens_add'], axis=1)\n",
        "\n",
        "X = df[['campaign_id', 'traffic_source_id',\n",
        "       'visitor_device_browser', 'visitor_device_hardware_family',\n",
        "       'visitor_device_hardware_model', 'visitor_device_hardware_vendor',\n",
        "       'visitor_device_os_family', 'visitor_device_os_vendor',\n",
        "       'visitor_device_os_version', 'visitor_device_type',\n",
        "       'visitor_geo_location_cityName', 'visitor_geo_location_connection_type',\n",
        "       'visitor_geo_location_countryCode', 'visitor_geo_location_isp',\n",
        "       'visitor_geo_location_regionName', 'visitor_tokens_adh',\n",
        "       'visitor_tokens_cadid', 'visitor_tokens_adi', 'converted_yes',\n",
        "       'converted_no']]\n",
        "\n",
        "X = X.astype(str).to_numpy()\n",
        "y = df[[\"landing_page_id\"]].to_numpy()\n",
        "\n",
        "# encode string input values as integers\n",
        "encoded_x = None\n",
        "for i in range(0, X.shape[1]):\n",
        "    label_encoder = LabelEncoder()\n",
        "    feature = label_encoder.fit_transform(X[:,i])\n",
        "    feature = feature.reshape(X.shape[0], 1)\n",
        "    onehot_encoder = OrdinalEncoder()\n",
        "    feature = onehot_encoder.fit_transform(feature)\n",
        "    if encoded_x is None:\n",
        "        encoded_x = feature\n",
        "    else:\n",
        "        encoded_x = numpy.concatenate((encoded_x, feature), axis=1)\n",
        "#print(\"X shape: : \", encoded_x.shape)\n",
        "\n",
        "# encode string class values as integers\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder = label_encoder.fit(y)\n",
        "label_encoded_y = label_encoder.transform(y)\n",
        "dummy_y = np_utils.to_categorical(label_encoded_y)\n",
        "\n",
        "# split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(encoded_x, dummy_y, test_size=0.30, random_state=123)\n",
        "\n",
        "scaler=StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train=scaler.transform(X_train)\n",
        "X_test=scaler.transform(X_test)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "metadata": {
        "id": "34_vwhTyHQ3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fcf434a-319a-4159-e75a-b554b69649e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"landing_page_id\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjUqq-8BzL7C",
        "outputId": "e1f8b2c6-e6b6-422d-bd83-c3ee898d3e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "631d72ff99ba21001a8503fa    2624\n",
              "631d779999ba21001a850416    2618\n",
              "62566aa432b19a0164d802be    2598\n",
              "Name: landing_page_id, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQNf8hxqm1s3",
        "outputId": "79b38b25-02b9-4a5e-8bd3-44664f9b38ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7840, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generando el primer modelo sin optimizar los hiperparametros"
      ],
      "metadata": {
        "id": "VajQJMIipjHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Batch Size and Number of Epochs"
      ],
      "metadata": {
        "id": "Glnxs5qc9bka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición del modelo\n",
        "def modelo_mlp(): \n",
        "    model = Sequential()\n",
        "    model.add(Dense(20, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "53H2PhhOCR7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = modelo_mlp()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9H706zwz_3B",
        "outputId": "2078d2d5-8894-44c4-c73b-802133cdc6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 20)                420       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 63        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 483\n",
            "Trainable params: 483\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo con el dataset\n",
        "history=model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg-2_QQC0C74",
        "outputId": "2d87e973-b7e4-4a18-aaef-a0089e532ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 1.0686 - accuracy: 0.4233 - val_loss: 0.9053 - val_accuracy: 0.5480\n",
            "Epoch 2/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.8326 - accuracy: 0.5621 - val_loss: 0.7627 - val_accuracy: 0.5906\n",
            "Epoch 3/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.7343 - accuracy: 0.5878 - val_loss: 0.6999 - val_accuracy: 0.6033\n",
            "Epoch 4/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6912 - accuracy: 0.5977 - val_loss: 0.6708 - val_accuracy: 0.6139\n",
            "Epoch 5/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6077 - val_loss: 0.6529 - val_accuracy: 0.6101\n",
            "Epoch 6/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6113 - val_loss: 0.6395 - val_accuracy: 0.6148\n",
            "Epoch 7/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.6142 - val_loss: 0.6284 - val_accuracy: 0.6131\n",
            "Epoch 8/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.6266 - accuracy: 0.6197 - val_loss: 0.6186 - val_accuracy: 0.6178\n",
            "Epoch 9/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.6248 - val_loss: 0.6097 - val_accuracy: 0.6220\n",
            "Epoch 10/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6060 - accuracy: 0.6292 - val_loss: 0.6016 - val_accuracy: 0.6233\n",
            "Epoch 11/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6347 - val_loss: 0.5942 - val_accuracy: 0.6237\n",
            "Epoch 12/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.6387 - val_loss: 0.5874 - val_accuracy: 0.6271\n",
            "Epoch 13/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6461 - val_loss: 0.5811 - val_accuracy: 0.6267\n",
            "Epoch 14/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.6496 - val_loss: 0.5754 - val_accuracy: 0.6297\n",
            "Epoch 15/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.6514 - val_loss: 0.5703 - val_accuracy: 0.6348\n",
            "Epoch 16/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.6583 - val_loss: 0.5655 - val_accuracy: 0.6412\n",
            "Epoch 17/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.6591 - val_loss: 0.5613 - val_accuracy: 0.6424\n",
            "Epoch 18/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.6624 - val_loss: 0.5578 - val_accuracy: 0.6450\n",
            "Epoch 19/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.6644 - val_loss: 0.5545 - val_accuracy: 0.6463\n",
            "Epoch 20/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.6658 - val_loss: 0.5514 - val_accuracy: 0.6433\n",
            "Epoch 21/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.6711 - val_loss: 0.5489 - val_accuracy: 0.6454\n",
            "Epoch 22/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.6687 - val_loss: 0.5468 - val_accuracy: 0.6463\n",
            "Epoch 23/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5377 - accuracy: 0.6691 - val_loss: 0.5448 - val_accuracy: 0.6475\n",
            "Epoch 24/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.6702 - val_loss: 0.5430 - val_accuracy: 0.6471\n",
            "Epoch 25/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.6709 - val_loss: 0.5416 - val_accuracy: 0.6446\n",
            "Epoch 26/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.6740 - val_loss: 0.5402 - val_accuracy: 0.6450\n",
            "Epoch 27/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.6753 - val_loss: 0.5390 - val_accuracy: 0.6471\n",
            "Epoch 28/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.6764 - val_loss: 0.5379 - val_accuracy: 0.6501\n",
            "Epoch 29/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.6775 - val_loss: 0.5370 - val_accuracy: 0.6526\n",
            "Epoch 30/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.6778 - val_loss: 0.5360 - val_accuracy: 0.6509\n",
            "Epoch 31/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.6786 - val_loss: 0.5351 - val_accuracy: 0.6514\n",
            "Epoch 32/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.6778 - val_loss: 0.5343 - val_accuracy: 0.6501\n",
            "Epoch 33/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.6786 - val_loss: 0.5336 - val_accuracy: 0.6471\n",
            "Epoch 34/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.6777 - val_loss: 0.5329 - val_accuracy: 0.6475\n",
            "Epoch 35/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.6782 - val_loss: 0.5323 - val_accuracy: 0.6471\n",
            "Epoch 36/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.6780 - val_loss: 0.5319 - val_accuracy: 0.6441\n",
            "Epoch 37/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.6808 - val_loss: 0.5316 - val_accuracy: 0.6463\n",
            "Epoch 38/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.6809 - val_loss: 0.5313 - val_accuracy: 0.6446\n",
            "Epoch 39/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.6813 - val_loss: 0.5310 - val_accuracy: 0.6454\n",
            "Epoch 40/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.6831 - val_loss: 0.5307 - val_accuracy: 0.6467\n",
            "Epoch 41/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.6831 - val_loss: 0.5306 - val_accuracy: 0.6480\n",
            "Epoch 42/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.6822 - val_loss: 0.5304 - val_accuracy: 0.6480\n",
            "Epoch 43/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.6817 - val_loss: 0.5302 - val_accuracy: 0.6480\n",
            "Epoch 44/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.6815 - val_loss: 0.5302 - val_accuracy: 0.6475\n",
            "Epoch 45/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.6817 - val_loss: 0.5299 - val_accuracy: 0.6488\n",
            "Epoch 46/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.6824 - val_loss: 0.5296 - val_accuracy: 0.6471\n",
            "Epoch 47/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.6839 - val_loss: 0.5295 - val_accuracy: 0.6458\n",
            "Epoch 48/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.6844 - val_loss: 0.5294 - val_accuracy: 0.6454\n",
            "Epoch 49/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5107 - accuracy: 0.6826 - val_loss: 0.5294 - val_accuracy: 0.6454\n",
            "Epoch 50/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.6829 - val_loss: 0.5294 - val_accuracy: 0.6441\n",
            "Epoch 51/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.6829 - val_loss: 0.5293 - val_accuracy: 0.6454\n",
            "Epoch 52/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.6826 - val_loss: 0.5294 - val_accuracy: 0.6458\n",
            "Epoch 53/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.6831 - val_loss: 0.5294 - val_accuracy: 0.6450\n",
            "Epoch 54/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.6835 - val_loss: 0.5294 - val_accuracy: 0.6429\n",
            "Epoch 55/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5077 - accuracy: 0.6837 - val_loss: 0.5294 - val_accuracy: 0.6416\n",
            "Epoch 56/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.6848 - val_loss: 0.5293 - val_accuracy: 0.6441\n",
            "Epoch 57/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.6846 - val_loss: 0.5293 - val_accuracy: 0.6437\n",
            "Epoch 58/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.6853 - val_loss: 0.5293 - val_accuracy: 0.6433\n",
            "Epoch 59/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.6862 - val_loss: 0.5292 - val_accuracy: 0.6420\n",
            "Epoch 60/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.6862 - val_loss: 0.5291 - val_accuracy: 0.6441\n",
            "Epoch 61/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.6864 - val_loss: 0.5291 - val_accuracy: 0.6437\n",
            "Epoch 62/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.6868 - val_loss: 0.5291 - val_accuracy: 0.6437\n",
            "Epoch 63/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.6870 - val_loss: 0.5291 - val_accuracy: 0.6446\n",
            "Epoch 64/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5039 - accuracy: 0.6879 - val_loss: 0.5292 - val_accuracy: 0.6433\n",
            "Epoch 65/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5035 - accuracy: 0.6888 - val_loss: 0.5291 - val_accuracy: 0.6420\n",
            "Epoch 66/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.6902 - val_loss: 0.5291 - val_accuracy: 0.6416\n",
            "Epoch 67/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.6886 - val_loss: 0.5292 - val_accuracy: 0.6420\n",
            "Epoch 68/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.6906 - val_loss: 0.5292 - val_accuracy: 0.6429\n",
            "Epoch 69/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.6904 - val_loss: 0.5293 - val_accuracy: 0.6416\n",
            "Epoch 70/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.6902 - val_loss: 0.5290 - val_accuracy: 0.6407\n",
            "Epoch 71/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.6897 - val_loss: 0.5291 - val_accuracy: 0.6412\n",
            "Epoch 72/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5009 - accuracy: 0.6902 - val_loss: 0.5292 - val_accuracy: 0.6420\n",
            "Epoch 73/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.6908 - val_loss: 0.5292 - val_accuracy: 0.6403\n",
            "Epoch 74/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.6921 - val_loss: 0.5292 - val_accuracy: 0.6399\n",
            "Epoch 75/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.6915 - val_loss: 0.5292 - val_accuracy: 0.6403\n",
            "Epoch 76/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.6919 - val_loss: 0.5293 - val_accuracy: 0.6399\n",
            "Epoch 77/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.6919 - val_loss: 0.5293 - val_accuracy: 0.6382\n",
            "Epoch 78/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.6922 - val_loss: 0.5292 - val_accuracy: 0.6390\n",
            "Epoch 79/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.6939 - val_loss: 0.5291 - val_accuracy: 0.6395\n",
            "Epoch 80/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4982 - accuracy: 0.6937 - val_loss: 0.5291 - val_accuracy: 0.6403\n",
            "Epoch 81/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.6939 - val_loss: 0.5290 - val_accuracy: 0.6399\n",
            "Epoch 82/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.6959 - val_loss: 0.5290 - val_accuracy: 0.6386\n",
            "Epoch 83/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.6948 - val_loss: 0.5289 - val_accuracy: 0.6412\n",
            "Epoch 84/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.6952 - val_loss: 0.5288 - val_accuracy: 0.6403\n",
            "Epoch 85/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.6933 - val_loss: 0.5290 - val_accuracy: 0.6412\n",
            "Epoch 86/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.6935 - val_loss: 0.5289 - val_accuracy: 0.6416\n",
            "Epoch 87/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.6933 - val_loss: 0.5289 - val_accuracy: 0.6420\n",
            "Epoch 88/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.6944 - val_loss: 0.5288 - val_accuracy: 0.6412\n",
            "Epoch 89/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.6941 - val_loss: 0.5289 - val_accuracy: 0.6399\n",
            "Epoch 90/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.6948 - val_loss: 0.5289 - val_accuracy: 0.6373\n",
            "Epoch 91/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.6952 - val_loss: 0.5288 - val_accuracy: 0.6373\n",
            "Epoch 92/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.6961 - val_loss: 0.5290 - val_accuracy: 0.6386\n",
            "Epoch 93/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.6959 - val_loss: 0.5290 - val_accuracy: 0.6382\n",
            "Epoch 94/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.6970 - val_loss: 0.5291 - val_accuracy: 0.6373\n",
            "Epoch 95/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.6972 - val_loss: 0.5292 - val_accuracy: 0.6373\n",
            "Epoch 96/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.6968 - val_loss: 0.5293 - val_accuracy: 0.6369\n",
            "Epoch 97/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.6953 - val_loss: 0.5294 - val_accuracy: 0.6382\n",
            "Epoch 98/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.6968 - val_loss: 0.5293 - val_accuracy: 0.6386\n",
            "Epoch 99/100\n",
            "172/172 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.6959 - val_loss: 0.5295 - val_accuracy: 0.6395\n",
            "Epoch 100/100\n",
            "172/172 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.6970 - val_loss: 0.5295 - val_accuracy: 0.6386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Precisión Entrenamiento: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Precisión Prueba:  {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrxc9-tF0zyI",
        "outputId": "e333d227-2d96-469b-9f0b-691567b403c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión Entrenamiento: 0.7032\n",
            "Precisión Prueba:  0.6386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "from numpy import array\n",
        "# plot train and validation loss\n",
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.plot(history.history['val_loss'])\n",
        "pyplot.title('model train vs validation loss')\n",
        "pyplot.ylabel('loss')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.legend(['train', 'validation'], loc='upper right')\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "a-wqYGpz027I",
        "outputId": "35aea84f-027f-4439-e46b-e9bdbcc6d786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generando el primer modelo optimizando los hiperparametros"
      ],
      "metadata": {
        "id": "VqTcEZBq1DMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXiarNGO7Pim",
        "outputId": "13b23e10-1714-47e1-fc92-49fac9afe946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.9.1)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.38.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (2.14.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.50.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.2)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner\n",
            "Successfully installed jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Destroy Old Oracle\n",
        "!rm -rf tuning-mlp"
      ],
      "metadata": {
        "id": "JTxzF1F18SJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K \n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D,Flatten, Dropout \n",
        "from tensorflow.keras.models import Model, Sequential \n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.random import set_seed\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "import pickle\n",
        "import kerastuner as kt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMD2UH2K-IO0",
        "outputId": "cf8184e3-64d1-48d6-d1a5-d6668f246f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Tunable Model\n",
        "def mlp_model_builder(hp):\n",
        "  model = Sequential()\n",
        " \n",
        "  \n",
        "  model.add(Dense(units = hp.Int('dense-bot', min_value=1, max_value=25, step=16), input_shape=(20,), activation='relu'))\n",
        "  for i in range(hp.Int('num_dense_layers', 1, 2)):\n",
        "    model.add(Dense(units=hp.Int('dense_' + str(i), min_value=50, max_value=100, step=25), activation='relu'))\n",
        "    model.add(Dropout(hp.Choice('dropout_'+ str(i), values=[0.0, 0.1, 0.2])))\n",
        "  model.add(Dense(3,activation=\"softmax\"))\n",
        "\n",
        "  hp_optimizer=hp.Choice('Optimizer', values=['Adam', 'SGD'])\n",
        "\n",
        "  if hp_optimizer == 'Adam':\n",
        "      hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3])\n",
        "  elif hp_optimizer == 'SGD':\n",
        "      hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3])\n",
        "      nesterov=True\n",
        "      momentum=0.9\n",
        "\n",
        "  model.compile( optimizer=hp_optimizer,loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "bKnQH0Um09__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "random_seed = 8\n",
        "tf.random.set_seed = random_seed\n",
        "np.random.seed(random_seed)"
      ],
      "metadata": {
        "id": "W0Fda4Jc-crr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overload arguments with our custom metric.\n",
        "tuner_mlp = kt.tuners.BayesianOptimization(\n",
        "    mlp_model_builder,\n",
        "    seed=random_seed,\n",
        "    objective='val_loss',\n",
        "    max_trials=30,\n",
        "    directory='.',\n",
        "    project_name='tuning-mlp')"
      ],
      "metadata": {
        "id": "9leiCzmA-Ort"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Search Space \n",
        "tuner_mlp.search(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1CzNxXx-frc",
        "outputId": "1cd94429-09bd-4f9b-dca9-4a66206e1555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 01m 23s]\n",
            "val_loss: 0.5317756533622742\n",
            "\n",
            "Best val_loss So Far: 0.5106295943260193\n",
            "Total elapsed time: 00h 36m 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_mlp_hyperparameters = tuner_mlp.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_mlp_hyperparameters.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl7iMuCg-oSg",
        "outputId": "16a23347-0d08-4f7d-b5cc-c19f43d85455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyper-parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense-bot': 17,\n",
              " 'num_dense_layers': 2,\n",
              " 'dense_0': 50,\n",
              " 'dropout_0': 0.2,\n",
              " 'Optimizer': 'Adam',\n",
              " 'learning_rate': 0.001,\n",
              " 'dense_1': 100,\n",
              " 'dropout_1': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_mlp = Sequential()\n",
        "model_mlp.add(Dense(best_mlp_hyperparameters['dense-bot'], input_shape=(20,), activation='relu'))\n",
        "for i in range(best_mlp_hyperparameters['num_dense_layers']):\n",
        "  model_mlp.add(Dense(units=best_mlp_hyperparameters['dense_' +str(i)], activation='relu'))\n",
        "  model_mlp.add(Dropout(rate=best_mlp_hyperparameters['dropout_' +str(i)]))\n",
        "model_mlp.add(Dense(3,activation=\"softmax\"))\n",
        "\n",
        "model_mlp.compile(optimizer=best_mlp_hyperparameters['Optimizer'], \n",
        "                                                 loss='categorical_crossentropy', \n",
        "                                                 metrics=['accuracy'])\n",
        "history_mlp= model_mlp.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_Onw5RVIOcD",
        "outputId": "a56834eb-6565-4ada-f428-a4b9b2d8e8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.9112 - accuracy: 0.4971 - val_loss: 0.6849 - val_accuracy: 0.6093\n",
            "Epoch 2/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.6689 - accuracy: 0.6115 - val_loss: 0.6200 - val_accuracy: 0.6284\n",
            "Epoch 3/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6318 - accuracy: 0.6217 - val_loss: 0.5998 - val_accuracy: 0.6233\n",
            "Epoch 4/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.6098 - accuracy: 0.6226 - val_loss: 0.5835 - val_accuracy: 0.6378\n",
            "Epoch 5/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5896 - accuracy: 0.6306 - val_loss: 0.5720 - val_accuracy: 0.6314\n",
            "Epoch 6/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5751 - accuracy: 0.6383 - val_loss: 0.5595 - val_accuracy: 0.6424\n",
            "Epoch 7/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5609 - accuracy: 0.6498 - val_loss: 0.5504 - val_accuracy: 0.6514\n",
            "Epoch 8/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5455 - accuracy: 0.6587 - val_loss: 0.5398 - val_accuracy: 0.6446\n",
            "Epoch 9/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5340 - accuracy: 0.6625 - val_loss: 0.5311 - val_accuracy: 0.6509\n",
            "Epoch 10/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5290 - accuracy: 0.6640 - val_loss: 0.5224 - val_accuracy: 0.6535\n",
            "Epoch 11/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5194 - accuracy: 0.6696 - val_loss: 0.5184 - val_accuracy: 0.6424\n",
            "Epoch 12/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5142 - accuracy: 0.6680 - val_loss: 0.5128 - val_accuracy: 0.6582\n",
            "Epoch 13/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5090 - accuracy: 0.6798 - val_loss: 0.5118 - val_accuracy: 0.6552\n",
            "Epoch 14/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.6757 - val_loss: 0.5118 - val_accuracy: 0.6535\n",
            "Epoch 15/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4993 - accuracy: 0.6804 - val_loss: 0.5092 - val_accuracy: 0.6501\n",
            "Epoch 16/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.5000 - accuracy: 0.6786 - val_loss: 0.5089 - val_accuracy: 0.6480\n",
            "Epoch 17/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4966 - accuracy: 0.6815 - val_loss: 0.5096 - val_accuracy: 0.6543\n",
            "Epoch 18/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4946 - accuracy: 0.6839 - val_loss: 0.5079 - val_accuracy: 0.6522\n",
            "Epoch 19/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4912 - accuracy: 0.6902 - val_loss: 0.5093 - val_accuracy: 0.6535\n",
            "Epoch 20/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4937 - accuracy: 0.6786 - val_loss: 0.5086 - val_accuracy: 0.6518\n",
            "Epoch 21/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4915 - accuracy: 0.6875 - val_loss: 0.5086 - val_accuracy: 0.6514\n",
            "Epoch 22/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4882 - accuracy: 0.6882 - val_loss: 0.5061 - val_accuracy: 0.6531\n",
            "Epoch 23/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4911 - accuracy: 0.6855 - val_loss: 0.5092 - val_accuracy: 0.6582\n",
            "Epoch 24/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4888 - accuracy: 0.6853 - val_loss: 0.5055 - val_accuracy: 0.6531\n",
            "Epoch 25/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4857 - accuracy: 0.6884 - val_loss: 0.5088 - val_accuracy: 0.6518\n",
            "Epoch 26/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4850 - accuracy: 0.6950 - val_loss: 0.5081 - val_accuracy: 0.6531\n",
            "Epoch 27/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4846 - accuracy: 0.6868 - val_loss: 0.5098 - val_accuracy: 0.6484\n",
            "Epoch 28/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4837 - accuracy: 0.6906 - val_loss: 0.5104 - val_accuracy: 0.6454\n",
            "Epoch 29/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4784 - accuracy: 0.6950 - val_loss: 0.5120 - val_accuracy: 0.6514\n",
            "Epoch 30/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4805 - accuracy: 0.6988 - val_loss: 0.5117 - val_accuracy: 0.6488\n",
            "Epoch 31/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4807 - accuracy: 0.6952 - val_loss: 0.5124 - val_accuracy: 0.6531\n",
            "Epoch 32/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4808 - accuracy: 0.6915 - val_loss: 0.5119 - val_accuracy: 0.6488\n",
            "Epoch 33/100\n",
            "172/172 [==============================] - 1s 5ms/step - loss: 0.4775 - accuracy: 0.6966 - val_loss: 0.5136 - val_accuracy: 0.6573\n",
            "Epoch 34/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4790 - accuracy: 0.6933 - val_loss: 0.5103 - val_accuracy: 0.6586\n",
            "Epoch 35/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4756 - accuracy: 0.7024 - val_loss: 0.5136 - val_accuracy: 0.6552\n",
            "Epoch 36/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4782 - accuracy: 0.6983 - val_loss: 0.5141 - val_accuracy: 0.6505\n",
            "Epoch 37/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4752 - accuracy: 0.6990 - val_loss: 0.5133 - val_accuracy: 0.6539\n",
            "Epoch 38/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4709 - accuracy: 0.7065 - val_loss: 0.5204 - val_accuracy: 0.6573\n",
            "Epoch 39/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4736 - accuracy: 0.7019 - val_loss: 0.5185 - val_accuracy: 0.6416\n",
            "Epoch 40/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4725 - accuracy: 0.7066 - val_loss: 0.5204 - val_accuracy: 0.6539\n",
            "Epoch 41/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4727 - accuracy: 0.6995 - val_loss: 0.5294 - val_accuracy: 0.6505\n",
            "Epoch 42/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4742 - accuracy: 0.7010 - val_loss: 0.5187 - val_accuracy: 0.6484\n",
            "Epoch 43/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4705 - accuracy: 0.7032 - val_loss: 0.5252 - val_accuracy: 0.6556\n",
            "Epoch 44/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4692 - accuracy: 0.7028 - val_loss: 0.5222 - val_accuracy: 0.6514\n",
            "Epoch 45/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4696 - accuracy: 0.7035 - val_loss: 0.5217 - val_accuracy: 0.6501\n",
            "Epoch 46/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4697 - accuracy: 0.7050 - val_loss: 0.5245 - val_accuracy: 0.6475\n",
            "Epoch 47/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4685 - accuracy: 0.7139 - val_loss: 0.5216 - val_accuracy: 0.6552\n",
            "Epoch 48/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4685 - accuracy: 0.7139 - val_loss: 0.5273 - val_accuracy: 0.6480\n",
            "Epoch 49/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4666 - accuracy: 0.7037 - val_loss: 0.5300 - val_accuracy: 0.6531\n",
            "Epoch 50/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4645 - accuracy: 0.7154 - val_loss: 0.5312 - val_accuracy: 0.6603\n",
            "Epoch 51/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4681 - accuracy: 0.7083 - val_loss: 0.5280 - val_accuracy: 0.6577\n",
            "Epoch 52/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4664 - accuracy: 0.7136 - val_loss: 0.5260 - val_accuracy: 0.6582\n",
            "Epoch 53/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4632 - accuracy: 0.7170 - val_loss: 0.5310 - val_accuracy: 0.6552\n",
            "Epoch 54/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4622 - accuracy: 0.7165 - val_loss: 0.5308 - val_accuracy: 0.6509\n",
            "Epoch 55/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4620 - accuracy: 0.7121 - val_loss: 0.5303 - val_accuracy: 0.6497\n",
            "Epoch 56/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4635 - accuracy: 0.7143 - val_loss: 0.5327 - val_accuracy: 0.6522\n",
            "Epoch 57/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4617 - accuracy: 0.7198 - val_loss: 0.5368 - val_accuracy: 0.6603\n",
            "Epoch 58/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4633 - accuracy: 0.7179 - val_loss: 0.5377 - val_accuracy: 0.6548\n",
            "Epoch 59/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.7167 - val_loss: 0.5385 - val_accuracy: 0.6518\n",
            "Epoch 60/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4646 - accuracy: 0.7125 - val_loss: 0.5356 - val_accuracy: 0.6590\n",
            "Epoch 61/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4587 - accuracy: 0.7254 - val_loss: 0.5394 - val_accuracy: 0.6509\n",
            "Epoch 62/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4581 - accuracy: 0.7203 - val_loss: 0.5388 - val_accuracy: 0.6522\n",
            "Epoch 63/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4533 - accuracy: 0.7294 - val_loss: 0.5481 - val_accuracy: 0.6556\n",
            "Epoch 64/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4560 - accuracy: 0.7227 - val_loss: 0.5460 - val_accuracy: 0.6552\n",
            "Epoch 65/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4561 - accuracy: 0.7199 - val_loss: 0.5472 - val_accuracy: 0.6552\n",
            "Epoch 66/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4590 - accuracy: 0.7230 - val_loss: 0.5480 - val_accuracy: 0.6633\n",
            "Epoch 67/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4567 - accuracy: 0.7254 - val_loss: 0.5443 - val_accuracy: 0.6505\n",
            "Epoch 68/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4511 - accuracy: 0.7283 - val_loss: 0.5492 - val_accuracy: 0.6497\n",
            "Epoch 69/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4530 - accuracy: 0.7261 - val_loss: 0.5530 - val_accuracy: 0.6475\n",
            "Epoch 70/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4507 - accuracy: 0.7287 - val_loss: 0.5582 - val_accuracy: 0.6467\n",
            "Epoch 71/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4541 - accuracy: 0.7267 - val_loss: 0.5528 - val_accuracy: 0.6509\n",
            "Epoch 72/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4517 - accuracy: 0.7241 - val_loss: 0.5496 - val_accuracy: 0.6518\n",
            "Epoch 73/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4506 - accuracy: 0.7270 - val_loss: 0.5526 - val_accuracy: 0.6484\n",
            "Epoch 74/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4504 - accuracy: 0.7351 - val_loss: 0.5606 - val_accuracy: 0.6492\n",
            "Epoch 75/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4481 - accuracy: 0.7312 - val_loss: 0.5646 - val_accuracy: 0.6505\n",
            "Epoch 76/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4493 - accuracy: 0.7343 - val_loss: 0.5636 - val_accuracy: 0.6467\n",
            "Epoch 77/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4493 - accuracy: 0.7341 - val_loss: 0.5647 - val_accuracy: 0.6484\n",
            "Epoch 78/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.7327 - val_loss: 0.5719 - val_accuracy: 0.6450\n",
            "Epoch 79/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4454 - accuracy: 0.7332 - val_loss: 0.5667 - val_accuracy: 0.6535\n",
            "Epoch 80/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4486 - accuracy: 0.7327 - val_loss: 0.5646 - val_accuracy: 0.6548\n",
            "Epoch 81/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4474 - accuracy: 0.7392 - val_loss: 0.5740 - val_accuracy: 0.6518\n",
            "Epoch 82/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4437 - accuracy: 0.7336 - val_loss: 0.5740 - val_accuracy: 0.6505\n",
            "Epoch 83/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4464 - accuracy: 0.7338 - val_loss: 0.5842 - val_accuracy: 0.6526\n",
            "Epoch 84/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4407 - accuracy: 0.7351 - val_loss: 0.5740 - val_accuracy: 0.6603\n",
            "Epoch 85/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4451 - accuracy: 0.7398 - val_loss: 0.5786 - val_accuracy: 0.6526\n",
            "Epoch 86/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4425 - accuracy: 0.7378 - val_loss: 0.5850 - val_accuracy: 0.6552\n",
            "Epoch 87/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4451 - accuracy: 0.7332 - val_loss: 0.5799 - val_accuracy: 0.6518\n",
            "Epoch 88/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4445 - accuracy: 0.7363 - val_loss: 0.5794 - val_accuracy: 0.6522\n",
            "Epoch 89/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4395 - accuracy: 0.7480 - val_loss: 0.5772 - val_accuracy: 0.6522\n",
            "Epoch 90/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4378 - accuracy: 0.7374 - val_loss: 0.5850 - val_accuracy: 0.6543\n",
            "Epoch 91/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4424 - accuracy: 0.7374 - val_loss: 0.5860 - val_accuracy: 0.6535\n",
            "Epoch 92/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4388 - accuracy: 0.7409 - val_loss: 0.5927 - val_accuracy: 0.6437\n",
            "Epoch 93/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4386 - accuracy: 0.7436 - val_loss: 0.5878 - val_accuracy: 0.6463\n",
            "Epoch 94/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4395 - accuracy: 0.7438 - val_loss: 0.5976 - val_accuracy: 0.6437\n",
            "Epoch 95/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4422 - accuracy: 0.7434 - val_loss: 0.5803 - val_accuracy: 0.6535\n",
            "Epoch 96/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4388 - accuracy: 0.7411 - val_loss: 0.5810 - val_accuracy: 0.6492\n",
            "Epoch 97/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4384 - accuracy: 0.7400 - val_loss: 0.5847 - val_accuracy: 0.6454\n",
            "Epoch 98/100\n",
            "172/172 [==============================] - 1s 3ms/step - loss: 0.4369 - accuracy: 0.7438 - val_loss: 0.5919 - val_accuracy: 0.6454\n",
            "Epoch 99/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4357 - accuracy: 0.7409 - val_loss: 0.5919 - val_accuracy: 0.6450\n",
            "Epoch 100/100\n",
            "172/172 [==============================] - 1s 4ms/step - loss: 0.4447 - accuracy: 0.7405 - val_loss: 0.5967 - val_accuracy: 0.6369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Precisión Entrenamiento: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Precisión Prueba:  {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y4w7VVZIOkD",
        "outputId": "9b548f83-e6f7-4899-9849-3a016d3f7c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión Entrenamiento: 0.7032\n",
            "Precisión Prueba:  0.6386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_mlp.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT3Oemx4IOng",
        "outputId": "da25a89b-e5e7-46f2-bf0c-19835b468ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 17)                357       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 50)                900       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               5100      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 3)                 303       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,660\n",
            "Trainable params: 6,660\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "VoeZQTkDKWoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import *"
      ],
      "metadata": {
        "id": "7Ds4n6OgMmcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import *"
      ],
      "metadata": {
        "id": "dsCdk5iTLioK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib"
      ],
      "metadata": {
        "id": "cIMg4RQ6Sko-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import *"
      ],
      "metadata": {
        "id": "x7QbVNvXqmqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_mlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FizcKX34PBFe",
        "outputId": "bedb8683-b84d-4553-ef6c-05513f5c0d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe5484bca10>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt(\n",
        "    hs={\n",
        "        'Best MLP': history_mlp\n",
        "    },\n",
        "    epochs=25,\n",
        "    loss='loss')\n",
        "\n",
        "plt(\n",
        "    hs={\n",
        "        'Best MLP': history_mlp\n",
        "    },\n",
        "    epochs=25, \n",
        "    metrics='accuracy')"
      ],
      "metadata": {
        "id": "Cu8-jrt2IOrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate accuracies\n",
        "mlp_train_loss, mlp_train_acc = model_mlp.evaluate(X_train,  y_train, verbose=2)\n",
        "print('\\nTrain accuracy:', mlp_train_acc)\n",
        "\n",
        "mlp_dev_loss, mlp_dev_acc = model_mlp.evaluate(X_train,  y_train, verbose=2)\n",
        "print('\\nValidation accuracy:', mlp_dev_acc)\n",
        "\n",
        "mlp_test_loss, mlp_test_acc = model_mlp.evaluate(X_test,  y_test, verbose=2)\n",
        "print('\\nTest accuracy:', mlp_test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP6jY3hLJo2q",
        "outputId": "b1d3ec6d-f3de-418f-9ffa-f93c0a87d909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 - 0s - loss: 0.4088 - accuracy: 0.7748 - 229ms/epoch - 1ms/step\n",
            "\n",
            "Train accuracy: 0.774781346321106\n",
            "172/172 - 0s - loss: 0.4088 - accuracy: 0.7748 - 233ms/epoch - 1ms/step\n",
            "\n",
            "Validation accuracy: 0.774781346321106\n",
            "74/74 - 0s - loss: 0.5967 - accuracy: 0.6369 - 135ms/epoch - 2ms/step\n",
            "\n",
            "Test accuracy: 0.636904776096344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_mlp_hyperparameters = tuner_mlp.get_best_hyperparameters(1)[0]\n",
        "print(\"Best Hyper-parameters\")\n",
        "best_mlp_hyperparameters.values"
      ],
      "metadata": {
        "id": "QmhLkNudv5LD",
        "outputId": "bc0add0f-a08a-4b6d-a6f4-62dd3506a142",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyper-parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dense-bot': 17,\n",
              " 'num_dense_layers': 2,\n",
              " 'dense_0': 50,\n",
              " 'dropout_0': 0.2,\n",
              " 'Optimizer': 'Adam',\n",
              " 'learning_rate': 0.001,\n",
              " 'dense_1': 100,\n",
              " 'dropout_1': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "DYKhs-3WUeWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import plot_confusion_matrix"
      ],
      "metadata": {
        "id": "T6eCLsxdUmKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['631d72ff99ba21001a8503fa', '631d779999ba21001a850416', '62566aa432b19a0164d802be']"
      ],
      "metadata": {
        "id": "gichzf3bVILf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=model_mlp.predict(X_test)\n",
        "\n",
        "plot_confusion_matrix(tf.argmax(predictions, axis = 1).numpy(), tf.argmax(y_test, axis = 1).numpy(),  classes=class_names, title='Confusion matrix on best MLP results')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yVdx1o4kJo6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "631d72ff99ba21001a8503fa    2624\n",
        "631d779999ba21001a850416    2618\n",
        "62566aa432b19a0164d802be "
      ],
      "metadata": {
        "id": "8uDjRvETJo9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test) \n",
        "y_pred=np.argmax(y_pred, axis=1)\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Jiii6bMFJpAK",
        "outputId": "fc6f317d-e935-4d28-b586-a97fb7705d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ8CejV0-oVd",
        "outputId": "6ca47461-a874-468b-e094-39e0a19e44e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       786\n",
            "           1       0.47      0.40      0.43       789\n",
            "           2       0.47      0.53      0.50       777\n",
            "\n",
            "    accuracy                           0.64      2352\n",
            "   macro avg       0.63      0.64      0.63      2352\n",
            "weighted avg       0.63      0.64      0.63      2352\n",
            "\n"
          ]
        }
      ]
    }
  ]
}